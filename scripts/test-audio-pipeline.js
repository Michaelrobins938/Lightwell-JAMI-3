#!/usr/bin/env node

/**
 * Terminal-based Audio Pipeline Debug Script
 * Run this to see exactly where your audio pipeline is breaking
 * 
 * Usage: node scripts/test-audio-pipeline.js
 */

const WebSocket = require('ws');

// Configuration - update these with your actual values
const CONFIG = {
  apiKey: process.env.OPENAI_API_KEY || 'your-api-key-here',
  model: 'gpt-4o-realtime-preview',
  voice: 'verse'  // âœ… FIXED: Changed from 'ember' to 'verse'
};

console.log('ğŸ” Audio Pipeline Debug Script Starting...\n');
console.log('ğŸ“‹ Configuration:');
console.log(`   Model: ${CONFIG.model}`);
console.log(`   Voice: ${CONFIG.voice}`);
console.log(`   API Key: ${CONFIG.apiKey ? '***' + CONFIG.apiKey.slice(-4) : 'NOT SET'}\n`);

if (!CONFIG.apiKey || CONFIG.apiKey === 'your-api-key-here') {
  console.error('âŒ Please set OPENAI_API_KEY environment variable or update the script');
  process.exit(1);
}

/**
 * Test 1: Basic WebSocket Connection
 */
async function testWebSocketConnection() {
  console.log('ğŸ§ª Test 1: WebSocket Connection');
  console.log('â”€'.repeat(50));
  
  try {
    // Note: OpenAI Realtime uses a different endpoint structure
    // This is a diagnostic test to see what endpoints are available
    console.log('ğŸ”Œ Attempting WebSocket connection...');
    
    // Test the realtime endpoint
    const response = await fetch('https://api.openai.com/v1/realtime', {
      method: 'GET',
      headers: {
        'Authorization': `Bearer ${CONFIG.apiKey}`,
        'Content-Type': 'application/json'
      }
    });
    
    console.log(`ğŸ“¡ HTTP Response: ${response.status} ${response.statusText}`);
    
    if (response.ok) {
      const data = await response.text();
      console.log('âœ… Endpoint accessible');
      console.log('ğŸ“„ Response preview:', data.substring(0, 200) + '...');
    } else {
      console.log('âŒ Endpoint not accessible');
      console.log('ğŸ’¡ This might indicate the endpoint requires POST or different parameters');
    }
    
  } catch (error) {
    console.error('âŒ Connection test failed:', error.message);
  }
  
  console.log('');
}

/**
 * Test 2: Session Initialization
 */
async function testSessionInit() {
  console.log('ğŸ§ª Test 2: Session Initialization');
  console.log('â”€'.repeat(50));
  
  try {
    console.log('ğŸ¯ Testing session creation with audio enabled...');
    
    // This is the payload that should enable audio deltas
    const sessionPayload = {
      type: "session.create",
      session: {
        model: CONFIG.model,
        voice: CONFIG.voice,
        modalities: ["audio", "text"],
        audio: {
          input: {
            type: "microphone",
            sampling_rate: 16000
          },
          output: {
            type: "speaker",
            sampling_rate: 24000
          }
        }
      }
    };
    
    console.log('ğŸ“¤ Session payload:');
    console.log(JSON.stringify(sessionPayload, null, 2));
    
    const response = await fetch('https://api.openai.com/v1/realtime', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${CONFIG.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(sessionPayload)
    });
    
    console.log(`ğŸ“¡ Session Response: ${response.status} ${response.statusText}`);
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… Session created successfully');
      console.log('ğŸ“„ Session data:', JSON.stringify(data, null, 2));
    } else {
      const errorText = await response.text();
      console.log('âŒ Session creation failed');
      console.log('ğŸ“„ Error details:', errorText);
    }
    
  } catch (error) {
    console.error('âŒ Session test failed:', error.message);
  }
  
  console.log('');
}

/**
 * Test 3: Audio Streaming Simulation
 */
async function testAudioStreaming() {
  console.log('ğŸ§ª Test 3: Audio Streaming Simulation');
  console.log('â”€'.repeat(50));
  
  try {
    console.log('ğŸµ Testing audio processing pipeline...');
    
    // Simulate a base64 audio chunk (this is what OpenAI would send)
    const mockBase64Audio = 'UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2/LDciUFLIHO8tiJNwgZaLvt559NEAxQp+PwtmMcBjiR1/LMeSwFJHfH8N2QQAoUXrTp66hVFApGn+DyvmwhBSuBzvLZiTYIG2m98OScTgwOUarm7blmGgU7k9n1unEiBC13yO/eizEIHWq+8+OWT';
    
    console.log('ğŸ”Š Mock audio chunk (base64):', mockBase64Audio.substring(0, 50) + '...');
    
    // Test base64 decoding
    try {
      const binary = Buffer.from(mockBase64Audio, 'base64');
      console.log('âœ… Base64 decoded successfully');
      console.log(`ğŸ“ Binary length: ${binary.length} bytes`);
      console.log(`ğŸµ Audio format: ${binary.length > 0 ? 'Valid' : 'Invalid'}`);
    } catch (error) {
      console.error('âŒ Base64 decoding failed:', error.message);
    }
    
    // Test audio buffer creation
    try {
      const audioBuffer = Buffer.alloc(1024); // Simulate audio buffer
      console.log('âœ… Audio buffer created');
      console.log(`ğŸ“¦ Buffer size: ${audioBuffer.length} bytes`);
    } catch (error) {
      console.error('âŒ Audio buffer creation failed:', error.message);
    }
    
  } catch (error) {
    console.error('âŒ Audio streaming test failed:', error.message);
  }
  
  console.log('');
}

/**
 * Test 4: API Capabilities Check
 */
async function testAPICapabilities() {
  console.log('ğŸ§ª Test 4: API Capabilities Check');
  console.log('â”€'.repeat(50));
  
  try {
    console.log('ğŸ” Checking OpenAI API capabilities...');
    
    // Test models endpoint to see what's available
    const response = await fetch('https://api.openai.com/v1/models', {
      headers: {
        'Authorization': `Bearer ${CONFIG.apiKey}`,
        'Content-Type': 'application/json'
      }
    });
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… Models endpoint accessible');
      
      // Look for realtime models
      const realtimeModels = data.data.filter(model => 
        model.id.includes('realtime') || model.id.includes('gpt-4o')
      );
      
      if (realtimeModels.length > 0) {
        console.log('ğŸ¯ Realtime models found:');
        realtimeModels.forEach(model => {
          console.log(`   - ${model.id} (${model.object})`);
        });
      } else {
        console.log('âš ï¸ No realtime models found');
        console.log('ğŸ’¡ Available models:', data.data.map(m => m.id).join(', '));
      }
    } else {
      console.log('âŒ Models endpoint not accessible');
    }
    
  } catch (error) {
    console.error('âŒ API capabilities check failed:', error.message);
  }
  
  console.log('');
}

/**
 * Main test runner
 */
async function runAllTests() {
  console.log('ğŸš€ Starting Audio Pipeline Diagnostics...\n');
  
  await testWebSocketConnection();
  await testSessionInit();
  await testAudioStreaming();
  await testAPICapabilities();
  
  console.log('ğŸ Diagnostics Complete!');
  console.log('\nğŸ“‹ Summary:');
  console.log('   â€¢ Check the results above to see where your pipeline breaks');
  console.log('   â€¢ If WebSocket connection fails, check your API key and endpoint');
  console.log('   â€¢ If session creation fails, check the payload format');
  console.log('   â€¢ If audio processing fails, check the base64 handling');
  console.log('   â€¢ If no realtime models found, check your OpenAI account access');
}

// Run the tests
runAllTests().catch(error => {
  console.error('ğŸ’¥ Test runner failed:', error);
  process.exit(1);
});
